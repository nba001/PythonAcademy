{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c2ae8b",
   "metadata": {},
   "source": [
    "# Lab (Day 2)\n",
    "\n",
    "## Goal\n",
    "Continue the **CURP-like mini-project** and turn yesterday's logic into a small **data pipeline**:\n",
    "\n",
    "1) Validate inputs with `if/else`  \n",
    "2) Refactor into reusable **functions**  \n",
    "3) Generate **fake data** using `faker`  \n",
    "4) Read and write data as **CSV** (simulating an Excel export)  \n",
    "5) Use `assert` to keep building **unit-test habits**  \n",
    "6) (Optional) Use `lambda` for sorting/filtering\n",
    "\n",
    "> Reminder: This is a training version (simplified), not an official RENAPO CURP generator.\n",
    "\n",
    "---\n",
    "\n",
    "## Required fields per record\n",
    "Each person is a `dict` with:\n",
    "- `first_name` (str)\n",
    "- `paternal_last` (str)\n",
    "- `maternal_last` (str)\n",
    "- `dob` (str: `\"YYYY-MM-DD\"`)\n",
    "- `sex` (str: `\"H\"` or `\"M\"`)\n",
    "- `state` (str: **2-letter abbreviation**, e.g. `\"DF\"`, `\"BC\"`, `\"BS\"`, `\"NE\"`)\n",
    "\n",
    "We will also load the official state abbreviations from the provided file:\n",
    "`ENTIDAD_FEDERATIVA_201602(ENTIDAD_FEDERATIVA).csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2743204d",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "\n",
    "Run the next cell. It includes:\n",
    "- normalization helper (provided)\n",
    "- constants\n",
    "- today's sample dataset (small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83122e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "\n",
    "VOWELS = set(\"AEIOU\")\n",
    "REQUIRED_FIELDS = {\"first_name\", \"paternal_last\", \"maternal_last\", \"dob\", \"sex\", \"state\"}\n",
    "\n",
    "people = [\n",
    "    {\n",
    "        \"first_name\": \"Concepción\",\n",
    "        \"paternal_last\": \"Salgado\",\n",
    "        \"maternal_last\": \"Briseño\",\n",
    "        \"dob\": \"1956-06-26\",\n",
    "        \"sex\": \"M\",\n",
    "        \"state\": \"DF\",\n",
    "    },\n",
    "    {\n",
    "        \"first_name\": \"Juan Carlos\",\n",
    "        \"paternal_last\": \"Hernández\",\n",
    "        \"maternal_last\": \"López\",\n",
    "        \"dob\": \"1998-11-03\",\n",
    "        \"sex\": \"H\",\n",
    "        \"state\": \"BC\",\n",
    "    },\n",
    "]\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    \"\"\"Uppercase, trim, remove diacritics, collapse spaces.\"\"\"\n",
    "    s = s.strip().upper()\n",
    "    s = unicodedata.normalize(\"NFD\", s)\n",
    "    s = \"\".join(ch for ch in s if unicodedata.category(ch) != \"Mn\")\n",
    "    s = \" \".join(s.split())\n",
    "    return s\n",
    "\n",
    "assert normalize_text(\"  María José  \") == \"MARIA JOSE\"\n",
    "assert normalize_text(\"Briseño\") == \"BRISENO\"\n",
    "print(\"Setup OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6935b02",
   "metadata": {},
   "source": [
    "## 1) Load State Abbreviations (CSV Catalog)\n",
    "\n",
    "We will load the file:\n",
    "\n",
    "`ENTIDAD_FEDERATIVA_201602(ENTIDAD_FEDERATIVA).csv`\n",
    "\n",
    "Columns:\n",
    "- `CATALOG_KEY`\n",
    "- `ENTIDAD_FEDERATIVA`\n",
    "- `ABREVIATURA`\n",
    "\n",
    "### Task\n",
    "1) Read the CSV using the `csv` module (not pandas today).\n",
    "2) Build a dictionary `state_name_to_code`:\n",
    "   - key: normalized entity name (e.g., `\"BAJA CALIFORNIA SUR\"`)\n",
    "   - value: abbreviation (e.g., `\"BS\"`)\n",
    "\n",
    "3) Create a second dictionary `state_code_to_name` for reverse lookup.\n",
    "\n",
    "### Checks\n",
    "- `\"BAJA CALIFORNIA SUR\"` should map to `\"BS\"`\n",
    "- `\"NO ESPECIFICADO\"` should map to `\"NE\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9462a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_path = Path(\"ENTIDAD_FEDERATIVA_201602(ENTIDAD_FEDERATIVA).csv\")\n",
    "\n",
    "# TODO:\n",
    "# - open the file with encoding='latin-1'\n",
    "# - use csv.DictReader\n",
    "# - build:\n",
    "#   state_name_to_code = {...}\n",
    "#   state_code_to_name = {...}\n",
    "\n",
    "state_name_to_code = {}\n",
    "state_code_to_name = {}\n",
    "\n",
    "# --- YOUR CODE HERE ---\n",
    "\n",
    "\n",
    "# --- Tests ---\n",
    "assert state_name_to_code[normalize_text(\"Baja California Sur\")] == \"BS\"\n",
    "assert state_name_to_code[normalize_text(\"No Especificado\")] == \"NE\"\n",
    "assert state_code_to_name[\"BC\"] == \"BAJA CALIFORNIA\"\n",
    "\n",
    "print(\"Exercise 1 OK. States loaded:\", len(state_name_to_code))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a917b",
   "metadata": {},
   "source": [
    "## 2) Input Validation with `if` + Exceptions\n",
    "\n",
    "Before building an identifier, we want to validate:\n",
    "\n",
    "- Required fields exist\n",
    "- `sex` must be `\"H\"` or `\"M\"`\n",
    "- `dob` must match `\"YYYY-MM-DD\"` shape (length 10, dashes at 4 and 7, digits elsewhere)\n",
    "- `state` must be a known 2-letter code (exists in `state_code_to_name`)\n",
    "\n",
    "### Task\n",
    "Implement `validate_person(person, state_code_to_name)`:\n",
    "- If invalid, raise `ValueError` with a clear message.\n",
    "- If valid, return `True`.\n",
    "\n",
    "### Checks\n",
    "Test with:\n",
    "1) a valid person (should return True)\n",
    "2) an invalid person with sex `\"X\"` (should raise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f9e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_person(person: dict, state_code_to_name: dict) -> bool:\n",
    "    # TODO:\n",
    "    # - check required fields\n",
    "    # - validate sex\n",
    "    # - validate dob format (simple structural checks)\n",
    "    # - validate state code in mapping\n",
    "    # - raise ValueError with message if any check fails\n",
    "    return True\n",
    "\n",
    "# Valid\n",
    "assert validate_person(people[0], state_code_to_name) is True\n",
    "\n",
    "# Invalid sex should raise\n",
    "bad = dict(people[0])\n",
    "bad[\"sex\"] = \"X\"\n",
    "\n",
    "try:\n",
    "    validate_person(bad, state_code_to_name)\n",
    "    assert False, \"Expected ValueError for invalid sex\"\n",
    "except ValueError as e:\n",
    "    print(\"Caught expected error:\", e)\n",
    "\n",
    "print(\"Exercise 2 OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afe12fd",
   "metadata": {},
   "source": [
    "## 3) Refactor: Extraction Functions (Reuse Lab 1 Logic)\n",
    "\n",
    "### Task\n",
    "Implement these functions:\n",
    "\n",
    "- `first_internal_vowel(s)`\n",
    "- `first_internal_consonant(s)`\n",
    "- `extract_yymmdd(dob)`\n",
    "\n",
    "Rules are the same as last time.\n",
    "Use `assert` tests as guidance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea236bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_internal_vowel(s: str) -> str:\n",
    "    # TODO\n",
    "    pass\n",
    "\n",
    "def first_internal_consonant(s: str) -> str:\n",
    "    # TODO\n",
    "    pass\n",
    "\n",
    "def extract_yymmdd(dob: str) -> str:\n",
    "    # TODO\n",
    "    pass\n",
    "\n",
    "# Tests\n",
    "assert first_internal_vowel(\"SALGADO\") == \"A\"\n",
    "assert first_internal_vowel(\"BCDFG\") == \"X\"\n",
    "\n",
    "assert first_internal_consonant(\"SALGADO\") == \"L\"\n",
    "assert first_internal_consonant(\"AEIOU\") == \"X\"\n",
    "\n",
    "assert extract_yymmdd(\"1956-06-26\") == \"560626\"\n",
    "assert extract_yymmdd(\"2004-01-09\") == \"040109\"\n",
    "\n",
    "print(\"Exercise 3 OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aa7948",
   "metadata": {},
   "source": [
    "## 4) Build a Clean `build_curp_like(person)` Function\n",
    "\n",
    "### Task\n",
    "Implement `build_curp_like(person, state_code_to_name)`:\n",
    "\n",
    "1) Validate with `validate_person(...)`\n",
    "2) Normalize the name fields\n",
    "3) Build:\n",
    "- block1 (4 chars)\n",
    "- date block (6 chars)\n",
    "- block2 (sex + state[:2]) (3 chars)\n",
    "- block3 (3 chars)\n",
    "- suffix `\"00\"`\n",
    "\n",
    "Return the final 18-character key.\n",
    "\n",
    "### Check\n",
    "For the first example record:\n",
    "`SABC560626MDFLRN00`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e1d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_curp_like(person: dict, state_code_to_name: dict) -> str:\n",
    "    # TODO:\n",
    "    # - validate first\n",
    "    # - normalize\n",
    "    # - build blocks\n",
    "    # - return key\n",
    "    pass\n",
    "\n",
    "key0 = build_curp_like(people[0], state_code_to_name)\n",
    "print(\"people[0] key:\", key0)\n",
    "\n",
    "assert key0 == \"SABC560626MDFLRN00\"\n",
    "assert len(key0) == 18\n",
    "\n",
    "print(\"Exercise 4 OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fde0dc",
   "metadata": {},
   "source": [
    "## 5) Generate Fake Data with `faker`\n",
    "\n",
    "We will use `faker` to generate realistic names.\n",
    "\n",
    "### Install (if needed)\n",
    "If `faker` is not installed in your environment, run:\n",
    "\n",
    "```python\n",
    "!pip -q install faker\n",
    "```\n",
    "\n",
    "### Task\n",
    "1) Create a `Faker` instance with Spanish locale: `\"es_MX\"`\n",
    "2) Generate **N** fake people dictionaries with required fields:\n",
    "   - `first_name`: use faker to generate a first name (you can take the first token if you get a full name)\n",
    "   - `paternal_last`, `maternal_last`: use faker last name\n",
    "   - `dob`: random date between 1950 and 2010 formatted as `\"YYYY-MM-DD\"`\n",
    "   - `sex`: random choice `\"H\"` or `\"M\"`\n",
    "   - `state`: choose a random state code from `state_code_to_name` keys\n",
    "\n",
    "3) Validate and build keys for all generated records.\n",
    "\n",
    "### Check\n",
    "- `len(fake_people) == N`\n",
    "- all keys have length 18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to install faker, uncomment:\n",
    "#       If you want to learn how to set up an environment for your project dependencies, ask me.\n",
    "# !pip -q install faker\n",
    "\n",
    "from random import choice\n",
    "from faker import Faker\n",
    "\n",
    "# TODO:\n",
    "# - faker = Faker(\"es_MX\")\n",
    "# - generate N fake people dicts into fake_people list\n",
    "\n",
    "N = 20\n",
    "faker = Faker(\"es_MX\")\n",
    "\n",
    "fake_people = []\n",
    "\n",
    "# --- YOUR CODE HERE ---\n",
    "# ptss Hint: faker can be used to suggest female or male names so you can skip random choosing\n",
    "# Hint 2: Also Date of Birth...\n",
    "# Hint 3: Faker is not good to suggest Mexican States, choose random for this ;)\n",
    "\n",
    "\n",
    "# Build keys\n",
    "fake_keys = []\n",
    "for p in fake_people:\n",
    "    k = build_curp_like(p, state_code_to_name)\n",
    "    fake_keys.append(k)\n",
    "\n",
    "print(\"Generated\", len(fake_people), \"fake records\")\n",
    "print(\"Sample keys:\", fake_keys[:5])\n",
    "\n",
    "assert len(fake_people) == N\n",
    "assert all(len(k) == 18 for k in fake_keys)\n",
    "\n",
    "print(\"Exercise 5 OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd182c",
   "metadata": {},
   "source": [
    "## 6) Write the Fake Dataset to CSV (Simulating Excel Export)\n",
    "\n",
    "In real life you might receive an Excel file. A common workflow is:\n",
    "Excel → \"Save as CSV\" → pipeline reads the CSV.\n",
    "\n",
    "### Task\n",
    "Write `fake_people` to a CSV file named `people_input.csv` with a header row.\n",
    "\n",
    "Required columns (exact names):\n",
    "`first_name,paternal_last,maternal_last,dob,sex,state`\n",
    "\n",
    "### Check\n",
    "- The file exists\n",
    "- The first row read back has all required keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d6ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = Path(\"people_input.csv\")\n",
    "\n",
    "# TODO:\n",
    "# - open output_csv for writing\n",
    "# - write header with REQUIRED_FIELDS in a stable order\n",
    "# - write each row from fake_people\n",
    "\n",
    "# --- YOUR CODE HERE ---\n",
    "\n",
    "\n",
    "assert output_csv.exists(), \"CSV file was not created\"\n",
    "\n",
    "# Read back first row for a sanity check\n",
    "# Really utf-8? are you sure? \n",
    "with output_csv.open(\"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    first_row = next(reader)\n",
    "\n",
    "print(\"First row from CSV:\", first_row)\n",
    "assert REQUIRED_FIELDS.issubset(first_row.keys())\n",
    "\n",
    "print(\"Exercise 6 OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dceccde",
   "metadata": {},
   "source": [
    "## 7) Read CSV and Run the Pipeline (with Exception Handling)\n",
    "\n",
    "### Task\n",
    "Implement `read_people_csv(path)`:\n",
    "- Read the CSV file into a list of dicts.\n",
    "- Ensure every dict has the required fields.\n",
    "\n",
    "Then implement `build_keys_pipeline(records)`:\n",
    "- For each record:\n",
    "  - Try to validate + build key\n",
    "  - If it fails: collect the error into an `errors` list (do not crash the whole pipeline)\n",
    "- Return `(keys, errors)`\n",
    "\n",
    "### Checks\n",
    "- keys list length + errors length should equal number of records\n",
    "- print at least 3 errors if you intentionally corrupt a few records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00235630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_people_csv(path: Path) -> list[dict]:\n",
    "    # TODO:\n",
    "    # - read CSV with DictReader\n",
    "    # - ensure required fields exist\n",
    "    # - return list of records\n",
    "    pass\n",
    "\n",
    "def build_keys_pipeline(records: list[dict]) -> tuple[list[str], list[str]]:\n",
    "    # TODO:\n",
    "    # - for each record, try build_curp_like\n",
    "    # - if success -> append key\n",
    "    # - if exception -> append readable error string\n",
    "    # - return (keys, errors)\n",
    "    pass\n",
    "\n",
    "records = read_people_csv(output_csv)\n",
    "\n",
    "# Intentionally corrupt 2 records to test exception handling\n",
    "records[0][\"sex\"] = \"X\"\n",
    "records[1][\"dob\"] = \"19AA-99-99\"\n",
    "\n",
    "keys, errors = build_keys_pipeline(records)\n",
    "\n",
    "print(\"Keys generated:\", len(keys))\n",
    "print(\"Errors captured:\", len(errors))\n",
    "print(\"Sample errors:\", errors[:3])\n",
    "\n",
    "assert len(keys) + len(errors) == len(records)\n",
    "\n",
    "print(\"Exercise 7 OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962569d",
   "metadata": {},
   "source": [
    "## 8) (Optional) `lambda` Practice — Sorting and Filtering\n",
    "\n",
    "### Task A\n",
    "Sort the **valid** keys (from `keys`) alphabetically.\n",
    "\n",
    "### Task B\n",
    "Filter records born in year >= 2000 using a `lambda`.\n",
    "\n",
    "Hints:\n",
    "- Year is `dob[:4]`\n",
    "- Convert to int: `int(year_str)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4caf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task A: sort keys\n",
    "sorted_keys = sorted(keys, key=lambda k: k)  # lambda is redundant here but shown for practice\n",
    "print(\"First 5 sorted keys:\", sorted_keys[:5])\n",
    "\n",
    "# Task B: filter records born >= 2000 (use the non-corrupted original CSV read again)\n",
    "records_clean = read_people_csv(output_csv)\n",
    "\n",
    "born_2000_plus = list(filter(lambda r: int(r[\"dob\"][:4]) >= 2000, records_clean))\n",
    "print(\"Born >= 2000:\", len(born_2000_plus))\n",
    "\n",
    "assert all(int(r[\"dob\"][:4]) >= 2000 for r in born_2000_plus)\n",
    "\n",
    "print(\"Exercise 8 OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf2b314",
   "metadata": {},
   "source": [
    "## Wrap-up / What’s next\n",
    "\n",
    "You now have the core of a pipeline:\n",
    "- load catalogs (state codes)\n",
    "- validate records\n",
    "- generate IDs\n",
    "- read/write CSV\n",
    "- handle errors without crashing\n",
    "\n",
    "Next lab we can:\n",
    "- read from a real CSV exported from Excel (your file)\n",
    "- write `people_output.csv` with an extra `curp_like` column\n",
    "- add logging + better error reporting\n",
    "- optionally implement a more realistic suffix strategy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
