{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffbf9101",
   "metadata": {},
   "source": [
    "# Exception Handling\n",
    "\n",
    "## Learning goals\n",
    "By the end of this notebook you should be able to:\n",
    "\n",
    "- Explain what an *exception* is and why it matters in Data Engineering and AI pipelines.\n",
    "- Use `try` / `except` to handle predictable failures *without hiding bugs*.\n",
    "- Use multiple `except` blocks, plus `else` and `finally`, to structure “happy path” vs “error path”.\n",
    "- Raise your own exceptions with `raise` for validation and schema checks.\n",
    "- Parse simple user/data inputs safely (avoiding `eval()`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a888cfd",
   "metadata": {},
   "source": [
    "## Why exception handling matters in Data Engineering\n",
    "\n",
    "In real pipelines, failures are normal:\n",
    "\n",
    "- Input files may be missing (`FileNotFoundError`)\n",
    "- Data may be malformed (`ValueError`, parsing errors)\n",
    "- Encodings can be wrong (`UnicodeDecodeError`)\n",
    "- External services can be unstable (timeouts, network errors)\n",
    "\n",
    "Your goal is **not** to “ignore errors”. Your goal is to:\n",
    "\n",
    "1. Handle *recoverable* problems with a clear fallback.\n",
    "2. Fail fast (with a clear message) when you cannot safely continue.\n",
    "3. Keep enough context to debug quickly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2681bb",
   "metadata": {},
   "source": [
    "## `try` / `except` fundamentals\n",
    "\n",
    "The <a href=\"https://docs.python.org/3/tutorial/errors.html\">`try`-`except`</a> statement lets you handle exceptions without the program terminating abruptly.\n",
    "\n",
    "- Put code that *might fail* inside `try`.\n",
    "- Catch **specific** exceptions in `except`.\n",
    "- Avoid using exception handling as a patch for unclear logic.\n",
    "\n",
    "**Best practice:** catch the most specific exception types you can reasonably predict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec2ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(numerator: float, denominator: float) -> float | None:\n",
    "    \"\"\"Return numerator/denominator, or None if denominator is zero.\"\"\"\n",
    "    try:\n",
    "        return numerator / denominator\n",
    "    except ZeroDivisionError:\n",
    "        return None\n",
    "\n",
    "print(safe_divide(10, 2))\n",
    "print(safe_divide(10, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5cb2e",
   "metadata": {},
   "source": [
    "## Catch specific exceptions first (and why “catch-all” is risky)\n",
    "\n",
    "You can catch different exceptions with multiple `except` blocks.\n",
    "\n",
    "- Put **specific** handlers first.\n",
    "- Use broad handlers (`Exception`) carefully, and typically only when you log context and re-raise or return a safe fallback.\n",
    "\n",
    "**Avoid:** bare `except:` (it can hide `KeyboardInterrupt`, `SystemExit`, and real programming bugs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f65ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_int(raw: str) -> int | None:\n",
    "    \"\"\"Parse an integer from a string, returning None if it is invalid.\"\"\"\n",
    "    try:\n",
    "        return int(raw)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "for s in [\"42\", \"003\", \"3.14\", \"hello\"]:\n",
    "    print(s, \"->\", parse_int(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66631bd1",
   "metadata": {},
   "source": [
    "## `else` and `finally`\n",
    "\n",
    "- `else` runs **only if no exception happened** in the `try` block.\n",
    "  - Useful to keep the “success path” separate from the error handling.\n",
    "- `finally` runs **no matter what**, even if an exception occurs.\n",
    "  - Useful for cleanup: closing files, releasing resources, disconnecting clients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_first_line(path: str) -> str:\n",
    "    f = None\n",
    "    try:\n",
    "        f = open(path, \"r\", encoding=\"utf-8\")\n",
    "    except FileNotFoundError:\n",
    "        return \"MISSING_FILE\"\n",
    "    else:\n",
    "        return f.readline().strip()\n",
    "    finally:\n",
    "        if f is not None:\n",
    "            f.close()\n",
    "\n",
    "print(read_first_line(\"data/input.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbcfe28",
   "metadata": {},
   "source": [
    "## Raising exceptions deliberately with `raise`\n",
    "\n",
    "Exceptions are not only accidental. You can **raise** them to enforce rules:\n",
    "\n",
    "- Validate function arguments\n",
    "- Validate dataset schema\n",
    "- Enforce business logic constraints\n",
    "\n",
    "In Data Engineering, this is a clean way to fail early when continuing would produce wrong outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def require_columns(df: pd.DataFrame, required: list[str]) -> None:\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "demo_df = pd.DataFrame({\"id\": [1, 2], \"value\": [10, 20]})\n",
    "require_columns(demo_df, [\"id\", \"value\"])\n",
    "print(\"Schema OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d4506",
   "metadata": {},
   "source": [
    "## Safe parsing: replace `eval()` with `ast.literal_eval()`\n",
    "\n",
    "**Important:** `eval()` executes arbitrary Python code. Using it on user input or external data is unsafe.\n",
    "\n",
    "If you only need to parse Python *literals* (numbers, strings, lists, dicts, tuples, booleans, None), use:\n",
    "\n",
    "- `ast.literal_eval()` (safe for literals)\n",
    "\n",
    "If parsing fails, fall back to treating the input as a raw string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def what_type_safe() -> None:\n",
    "    \"\"\"Read a value from input, safely parse literals, then print the resulting type.\"\"\"\n",
    "    raw = input(\"Type something (e.g. 123, 'hi', [1,2], {'a':1}): \").strip()\n",
    "    try:\n",
    "        value = ast.literal_eval(raw)\n",
    "    except (ValueError, SyntaxError):\n",
    "        value = raw  # fallback: keep as string\n",
    "\n",
    "    print(\"Parsed value:\", value)\n",
    "    print(\"Type:\", type(value))\n",
    "\n",
    "# Uncomment to run interactively:\n",
    "# what_type_safe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632226c",
   "metadata": {},
   "source": [
    "## Data Engineering mini-example: robust JSON line parsing\n",
    "\n",
    "A common pattern is to parse records one by one, skipping bad records while counting them.\n",
    "\n",
    "- Recoverable: a few malformed lines (skip and continue)\n",
    "- Non-recoverable: file missing (fail fast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a4b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Iterable\n",
    "\n",
    "def parse_json_lines(lines: Iterable[str]) -> tuple[list[dict], int]:\n",
    "    \"\"\"Parse JSON objects from an iterable of strings.\n",
    "\n",
    "    Returns:\n",
    "        (records, bad_count)\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    bad_count = 0\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            records.append(json.loads(line))\n",
    "        except json.JSONDecodeError:\n",
    "            bad_count += 1\n",
    "\n",
    "    return records, bad_count\n",
    "\n",
    "sample_lines = [\n",
    "    '{\"id\": 1, \"value\": 10}',\n",
    "    'not json',\n",
    "    '{\"id\": 2, \"value\": 20}'\n",
    "]\n",
    "\n",
    "records, bad = parse_json_lines(sample_lines)\n",
    "print(\"records:\", records)\n",
    "print(\"bad_count:\", bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d78d0",
   "metadata": {},
   "source": [
    "## Quick exercises (3–7 minutes each)\n",
    "\n",
    "1) **Safe parse**\n",
    "- Implement `safe_parse(raw: str)` using `ast.literal_eval`.\n",
    "- If parsing fails, return the original string.\n",
    "\n",
    "2) **Integer conversion**\n",
    "- Implement `to_int_or_none(raw: str)`:\n",
    "  - returns `int(raw)` if valid\n",
    "  - otherwise returns `None`\n",
    "\n",
    "3) **CSV load fallback**\n",
    "- Implement `load_csv_or_empty(path: str)`:\n",
    "  - if file exists, return `pd.read_csv(path)`\n",
    "  - if missing, return an empty DataFrame with columns `[\"id\", \"value\"]`\n",
    "\n",
    "4) **Schema validation**\n",
    "- Implement `validate_schema(df)` that raises `ValueError` if `[\"id\", \"value\"]` are missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75719072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggested solutions\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "def safe_parse(raw: str):\n",
    "    try:\n",
    "        return ast.literal_eval(raw)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return raw\n",
    "\n",
    "def to_int_or_none(raw: str):\n",
    "    try:\n",
    "        return int(raw)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def load_csv_or_empty(path: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except FileNotFoundError:\n",
    "        return pd.DataFrame(columns=[\"id\", \"value\"])\n",
    "    except pd.errors.ParserError:\n",
    "        return pd.DataFrame(columns=[\"id\", \"value\"])\n",
    "\n",
    "def validate_schema(df: pd.DataFrame) -> None:\n",
    "    required = [\"id\", \"value\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "print(\"Solutions cell executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd54a55f",
   "metadata": {},
   "source": [
    "> Content created by **Carlos Cruz-Maldonado**.  \n",
    "> Updated with additional best practices and Data Engineering examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labjupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "-1.-1.-1"
  },
  "vscode": {
   "interpreter": {
    "hash": "63b9296f6c17991b25300b923073fa09be5a7656821aad9d7c075cf9823913df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
