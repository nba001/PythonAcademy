{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffbf9101",
   "metadata": {},
   "source": [
    "# Exception Handling\n",
    "\n",
    "## Learning goals\n",
    "By the end of this notebook you should be able to:\n",
    "\n",
    "- Explain what an *exception* is and why it matters in Data Engineering and AI pipelines.\n",
    "- Use `try` / `except` to handle predictable failures *without hiding bugs*.\n",
    "- Use multiple `except` blocks, plus `else` and `finally`, to structure “happy path” vs “error path”.\n",
    "- Raise your own exceptions with `raise` for validation and schema checks.\n",
    "- Parse simple user/data inputs safely (avoiding `eval()`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a888cfd",
   "metadata": {},
   "source": [
    "## Why exception handling matters in Data Engineering\n",
    "\n",
    "In real pipelines, failures are normal:\n",
    "\n",
    "- Input files may be missing (`FileNotFoundError`)\n",
    "- Data may be malformed (`ValueError`, parsing errors)\n",
    "- Encodings can be wrong (`UnicodeDecodeError`)\n",
    "- External services can be unstable (timeouts, network errors)\n",
    "\n",
    "Your goal is **not** to “ignore errors”. Your goal is to:\n",
    "\n",
    "1. Handle *recoverable* problems with a clear fallback.\n",
    "2. Fail fast (with a clear message) when you cannot safely continue.\n",
    "3. Keep enough context to debug quickly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2681bb",
   "metadata": {},
   "source": [
    "## `try` / `except` fundamentals\n",
    "\n",
    "The <a href=\"https://docs.python.org/3/tutorial/errors.html\">`try`-`except`</a> statement lets you handle exceptions without the program terminating abruptly.\n",
    "\n",
    "- Put code that *might fail* inside `try`.\n",
    "- Catch **specific** exceptions in `except`.\n",
    "- Avoid using exception handling as a patch for unclear logic.\n",
    "\n",
    "**Best practice:** catch the most specific exception types you can reasonably predict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dec2ddce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def safe_divide(numerator: float, denominator: float) -> float | None : #Type Hinting, the function will return either float or None\n",
    "    \"\"\"Return numerator/denominator, or None if denominator is zero.\"\"\"\n",
    "    try:\n",
    "        return numerator / denominator\n",
    "    except ZeroDivisionError:\n",
    "        return None\n",
    "\n",
    "print(safe_divide(10, 2))\n",
    "print(safe_divide(10, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06027129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "My String Value\n"
     ]
    }
   ],
   "source": [
    "def safe_divide(numerator: float, denominator: float) -> float | str : #Type Hinting, the function will return either float or None\n",
    "    \"\"\"Return numerator/denominator, or None if denominator is zero.\"\"\"\n",
    "    try:\n",
    "        return numerator / denominator\n",
    "    except ZeroDivisionError:\n",
    "        return \"My String Value\"\n",
    "\n",
    "print(safe_divide(10, 2))\n",
    "print(safe_divide(10, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5cb2e",
   "metadata": {},
   "source": [
    "## Catch specific exceptions first (and why “catch-all” is risky)\n",
    "\n",
    "You can catch different exceptions with multiple `except` blocks.\n",
    "\n",
    "- Put **specific** handlers first.\n",
    "- Use broad handlers (`Exception`) carefully, and typically only when you log context and re-raise or return a safe fallback.\n",
    "\n",
    "**Avoid:** bare `except:` (it can hide `KeyboardInterrupt`, `SystemExit`, and real programming bugs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62f65ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 -> 42\n",
      "003 -> 3\n",
      "3.14 -> None\n",
      "hello -> None\n"
     ]
    }
   ],
   "source": [
    "def parse_int(raw: str) -> int | None:\n",
    "    \"\"\"Parse an integer from a string, returning None if it is invalid.\"\"\"\n",
    "    try:\n",
    "        return int(raw)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "for s in [\"42\", \"003\", \"3.14\", \"hello\"]:\n",
    "    print(s, \"->\", parse_int(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66631bd1",
   "metadata": {},
   "source": [
    "## `else` and `finally`\n",
    "\n",
    "- `else` runs **only if no exception happened** in the `try` block.\n",
    "  - Useful to keep the “success path” separate from the error handling.\n",
    "- `finally` runs **no matter what**, even if an exception occurs.\n",
    "  - Useful for cleanup: closing files, releasing resources, disconnecting clients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0ce8e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING_FILE\n"
     ]
    }
   ],
   "source": [
    "def read_first_line(path: str) -> str:\n",
    "    f = None\n",
    "    try:\n",
    "        f = open(path, \"r\", encoding=\"utf-8\")\n",
    "    except FileNotFoundError:\n",
    "        return \"MISSING_FILE\"\n",
    "    else:\n",
    "        return f.readline().strip()\n",
    "    finally:\n",
    "        if f is not None:\n",
    "            f.close()\n",
    "\n",
    "print(read_first_line(\"data/input.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbcfe28",
   "metadata": {},
   "source": [
    "## Raising exceptions deliberately with `raise`\n",
    "\n",
    "Exceptions are not only accidental. You can **raise** them to enforce rules:\n",
    "\n",
    "- Validate function arguments\n",
    "- Validate dataset schema\n",
    "- Enforce business logic constraints\n",
    "\n",
    "In Data Engineering, this is a clean way to fail early when continuing would produce wrong outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe6e9c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema OK!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def require_columns(df: pd.DataFrame, required: list[str]) -> None:\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "demo_df = pd.DataFrame({\"id\": [1, 2], \"value\": [10, 20]})\n",
    "require_columns(demo_df, [\"id\", \"value\"])\n",
    "# require_columns(demo_df, [\"id\", \"value1\"])\n",
    "print(\"Schema OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d4506",
   "metadata": {},
   "source": [
    "## Safe parsing: replace `eval()` with `ast.literal_eval()`\n",
    "\n",
    "**Important:** `eval()` executes arbitrary Python code. Using it on user input or external data is unsafe.\n",
    "\n",
    "If you only need to parse Python *literals* (numbers, strings, lists, dicts, tuples, booleans, None), use:\n",
    "\n",
    "- `ast.literal_eval()` (safe for literals)\n",
    "\n",
    "If parsing fails, fall back to treating the input as a raw string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e34c5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed value: hi\n",
      "Type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def what_type_safe() -> None:\n",
    "    \"\"\"Read a value from input, safely parse literals, then print the resulting type.\"\"\"\n",
    "    raw = input(\"Type something (e.g. 123, 'hi', [1,2], {'a':1}): \").strip()\n",
    "    try:\n",
    "        value = ast.literal_eval(raw)\n",
    "    except (ValueError, SyntaxError):\n",
    "        value = raw  # fallback: keep as string\n",
    "\n",
    "    print(\"Parsed value:\", value)\n",
    "    print(\"Type:\", type(value))\n",
    "\n",
    "# Uncomment to run interactively:\n",
    "what_type_safe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3a0eb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eval(\"print(1,2)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73d55e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ast.literal_eval(\"[23,232,'hello']\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632226c",
   "metadata": {},
   "source": [
    "## Data Engineering mini-example: robust JSON line parsing\n",
    "\n",
    "A common pattern is to parse records one by one, skipping bad records while counting them.\n",
    "\n",
    "- Recoverable: a few malformed lines (skip and continue)\n",
    "- Non-recoverable: file missing (fail fast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14a4b93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records: [{'id': 1, 'value': 10}, {'id': 2, 'value': 20}]\n",
      "bad_count: 1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Iterable\n",
    "\n",
    "def parse_json_lines(lines: Iterable[str]) -> tuple[list[dict], int]:\n",
    "    \"\"\"Parse JSON objects from an iterable of strings.\n",
    "\n",
    "    Returns:\n",
    "        (records, bad_count)\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    bad_count = 0\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            records.append(json.loads(line))\n",
    "        except json.JSONDecodeError:\n",
    "            bad_count += 1\n",
    "\n",
    "    return records, bad_count\n",
    "\n",
    "sample_lines = [\n",
    "    '{\"id\": 1, \"value\": 10}',\n",
    "    'not json',\n",
    "    '{\"id\": 2, \"value\": 20}'\n",
    "]\n",
    "\n",
    "records, bad = parse_json_lines(sample_lines)\n",
    "print(\"records:\", records)\n",
    "print(\"bad_count:\", bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d78d0",
   "metadata": {},
   "source": [
    "## Quick exercises (3–7 minutes each)\n",
    "\n",
    "1) **Safe parse**\n",
    "- Implement `safe_parse(raw: str)` using `ast.literal_eval`.\n",
    "- If parsing fails, return the original string.\n",
    "\n",
    "2) **Integer conversion**\n",
    "- Implement `to_int_or_none(raw: str)`:\n",
    "  - returns `int(raw)` if valid\n",
    "  - otherwise returns `None`\n",
    "\n",
    "3) **CSV load fallback**\n",
    "- Implement `load_csv_or_empty(path: str)`:\n",
    "  - if file exists, return `pd.read_csv(path)`\n",
    "  - if missing, return an empty DataFrame with columns `[\"id\", \"value\"]`\n",
    "\n",
    "4) **Schema validation**\n",
    "- Implement `validate_schema(df)` that raises `ValueError` if `[\"id\", \"value\"]` are missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0f422e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : <class 'int'>, Value = 123 \n",
      "Type : <class 'str'>, Value = str(list(range(5))) \n",
      "Type : <class 'list'>, Value = [1, 2, 3, 4] \n"
     ]
    }
   ],
   "source": [
    "# 1) **Safe parse**\n",
    "# - Implement `safe_parse(raw: str)` using `ast.literal_eval`.\n",
    "# - If parsing fails, return the original string.\n",
    "import ast\n",
    "\n",
    "def safe_parse(raw: str):\n",
    "    try:\n",
    "        return ast.literal_eval(raw)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return raw\n",
    "print(f'Type : { type(safe_parse(\"123\")) }, Value = { safe_parse(\"123\") } ')\n",
    "print(f'Type : { type(safe_parse(\"str(list(range(5)))\")) }, Value = { safe_parse(\"str(list(range(5)))\") } ')\n",
    "print(f'Type : { type(safe_parse(\"[1,2,3,4]\")) }, Value = { safe_parse(\"[1,2,3,4]\") } ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9628597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 2 None 3\n"
     ]
    }
   ],
   "source": [
    "# 2) **Integer conversion**\n",
    "# - Implement `to_int_or_none(raw: str)`:\n",
    "#   - returns `int(raw)` if valid\n",
    "#   - otherwise returns `None`\n",
    "\n",
    "def to_int_or_none(raw:str):\n",
    "    try:\n",
    "        return int(raw)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "print(to_int_or_none(23), to_int_or_none(2.4), to_int_or_none(\"Hello\"), to_int_or_none(\"3\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5e7955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, ValueError]\n",
      "Index: [] \n",
      "------------\n",
      "    id   name  score\n",
      "0   1  Alice     98\n",
      "1   2    Bob     87\n",
      "2   3  Carol     91\n",
      "3   4    Dan     73\n",
      "4   5    Eve     88\n"
     ]
    }
   ],
   "source": [
    "# 3) **CSV load fallback**\n",
    "# - Implement `load_csv_or_empty(path: str)`:\n",
    "#   - if file exists, return `pd.read_csv(path)`\n",
    "#   - if missing, return an empty DataFrame with columns `[\"id\", \"value\"]`\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "def load_csv_or_empty(path: str):\n",
    "    try:\n",
    "       return pd.read_csv(path)\n",
    "    except FileNotFoundError:\n",
    "       return pd.DataFrame(columns=['id','ValueError'])\n",
    "    except pd.errors.ParserError:\n",
    "       return pd.DataFrame(columns=['id','ValueError'])\n",
    "\n",
    "print(load_csv_or_empty(\"sample.txt\"),\"\\n------------\\n\", load_csv_or_empty(str(Path.cwd()) + \"/data/sample.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d717623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# 4) **Schema validation**\n",
    "# - Implement `validate_schema(df)` that raises `ValueError` if `[\"id\", \"value\"]` are missing.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def validate_schema(df:pd.DataFrame):\n",
    "    required_columns = ['id','value']\n",
    "    missing_columns = [c for c in required_columns if c not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(\"Required columns [id, value] are missing.\")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'id':[1,2,3],\n",
    "     'value':[\"Apple\",\"Mango\",\"Banana\"]}\n",
    ")\n",
    "print(validate_schema(df))\n",
    "#print(validate_schema(pd.DataFrame()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "75719072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solutions cell executed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Suggested solutions\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "def safe_parse(raw: str):\n",
    "    try:\n",
    "        return ast.literal_eval(raw)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return raw\n",
    "\n",
    "def to_int_or_none(raw: str):\n",
    "    try:\n",
    "        return int(raw)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def load_csv_or_empty(path: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except FileNotFoundError:\n",
    "        return pd.DataFrame(columns=[\"id\", \"value\"])\n",
    "    except pd.errors.ParserError:\n",
    "        return pd.DataFrame(columns=[\"id\", \"value\"])\n",
    "\n",
    "def validate_schema(df: pd.DataFrame) -> None:\n",
    "    required = [\"id\", \"value\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "print(\"Solutions cell executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd54a55f",
   "metadata": {},
   "source": [
    "> Content created by **Carlos Cruz-Maldonado**.  \n",
    "> Updated with additional best practices and Data Engineering examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (trainings)",
   "language": "python",
   "name": "trainings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "63b9296f6c17991b25300b923073fa09be5a7656821aad9d7c075cf9823913df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
